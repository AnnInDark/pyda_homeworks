{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continent-fisher",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "Для датафрейма log из материалов занятия создайте столбец source_type по следующим правилам:\n",
    "\n",
    "- если источник traffic_source равен yandex или google, то в source_type ставится organic\n",
    "- для источников paid и email из России - ставим ad\n",
    "- для источников paid и email не из России - ставим other\n",
    "- все остальные варианты берем из traffic_source без изменений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-kennedy",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sixth-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vlog = pd.read_csv('/home/annindark/_pandas1_datasets/visit_log.csv', delimiter=';')\n",
    "\n",
    "# Подготовка ф-ции обработки сорса\n",
    "def SourceType (row):\n",
    "    if row['traffic_source'] in ('yandex', 'google'):\n",
    "        return 'organic'\n",
    "    elif row['traffic_source'] in ('email', 'paid'):\n",
    "        if row['region'] == 'Russia':\n",
    "            return 'ad'\n",
    "        else:\n",
    "            return 'other'\n",
    "    else:\n",
    "        return row['traffic_source']\n",
    "\n",
    "# Обогащение датафрейма\n",
    "vlog['source_type'] = vlog.apply(lambda x: SourceType(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-railway",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "В файле URLs.txt содержатся url страниц новостного сайта.\n",
    "Вам необходимо отфильтровать его по адресам страниц с текстами новостей.\n",
    "Известно, что шаблон страницы новостей имеет внутри url следующую конструкцию: /, затем 8 цифр, затем дефис.\n",
    "\n",
    "Выполните следующие действия:\n",
    "\n",
    "1. Прочитайте содержимое файла с датафрейм\n",
    "2. Отфильтруйте страницы с текстом новостей, используя метод str.contains и регулярное выражение в соответствии с заданным шаблоном"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-primary",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "urls = pd.read_csv('/home/annindark/_pandas1_datasets/URLs.txt')\n",
    "\n",
    "urls.loc[urls.url.str.contains(r'/[0-9]{8,8}-')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-scoop",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Используйте файл с оценками фильмов ratings.csv. \n",
    "Посчитайте среднее время жизни пользователей, которые выставили более 100 оценок. \n",
    "Под временем жизни понимается разница между максимальным и минимальным значением столбца timestamp для данного значения userId.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-providence",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rate = pd.read_csv('/home/annindark/_pandas1_datasets/ml-latest-small/ratings.csv')\n",
    "\n",
    "# собираем кол-во оценок, мин и макс дату на юзера\n",
    "rate = rate.groupby('userId').agg({'timestamp': ['min','max', 'count']})\n",
    "# Отфильтровываем нужных (боьлше 100 оценок) (положить в предыдущую команде сразу не получилось - ругался, что не знает такие ключи/названия столбцов)\n",
    "rate = rate.loc[rate['timestamp']['count'] > 100]\n",
    "\n",
    "# Считаем LT в рамках каждого юзера\n",
    "rate['lt'] = rate.apply(lambda x: pd.to_datetime(x['timestamp']['max'], unit='s')-pd.to_datetime(x['timestamp']['min'], unit='s'), axis=1)\n",
    "\n",
    "# Получаем конечный результат\n",
    "rate['lt'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-curtis",
   "metadata": {},
   "source": [
    "## Задание 4\n",
    "\n",
    "Дана статистика услуг перевозок клиентов компании по типам:\n",
    "```\n",
    "rzd - железнодорожные перевозки\n",
    "auto - автомобильные перевозки\n",
    "air - воздушные перевозки\n",
    "client_base - адреса клиентов\n",
    "```\n",
    "\n",
    "Необходимо сформировать две таблицы:\n",
    "- таблицу с тремя типами выручки для каждого client_id без указания адреса клиента\n",
    "- аналогичную таблицу по типам выручки с указанием адреса клиента\n",
    "\n",
    "_Обратите внимание, что в процессе объединения таблиц данные не должны теряться._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-plate",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "rzd = pd.DataFrame(\n",
    "    {\n",
    "        'client_id': [111, 112, 113, 114, 115],\n",
    "        'rzd_revenue': [1093, 2810, 10283, 5774, 981]\n",
    "    }\n",
    ")\n",
    "auto = pd.DataFrame(\n",
    "    {\n",
    "        'client_id': [113, 114, 115, 116, 117],\n",
    "        'auto_revenue': [57483, 83, 912, 4834, 98]\n",
    "    }\n",
    ")\n",
    "air = pd.DataFrame(\n",
    "    {\n",
    "        'client_id': [115, 116, 117, 118],\n",
    "        'air_revenue': [81, 4, 13, 173]\n",
    "    }\n",
    ")\n",
    "client_base = pd.DataFrame(\n",
    "    {\n",
    "        'client_id': [111, 112, 113, 114, 115, 116, 117, 118],\n",
    "        'address': ['Комсомольская 4', 'Энтузиастов 8а', 'Левобережная 1а', 'Мира 14', 'ЗЖБИиДК 1', \n",
    "                    'Строителей 18', 'Панфиловская 33', 'Мастеркова 4']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Выручка по клиентам\n",
    "client_base.merge(rzd, on='client_id' , how='left').merge(auto, on='client_id' , how='left').merge(air, on='client_id' , how='left').iloc[:,[0,2,3,4]].groupby('client_id').agg(sum)\n",
    "\n",
    "# Не уверена, что корректно поняла последнюю часть задания \n",
    "\n",
    "# Выручка по адресам\n",
    "client_base.merge(rzd, on='client_id' , how='left').merge(auto, on='client_id' , how='left').merge(air, on='client_id' , how='left').iloc[:,[1,2,3,4]].groupby('address').agg(sum)\n",
    "\n",
    "# Выручка по клиентам с адресами\n",
    "client_base.merge(rzd, on='client_id' , how='left').merge(auto, on='client_id' , how='left').merge(air, on='client_id' , how='left').groupby(['client_id', 'address']).agg(sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
